import pandas as pd
import dask.dataframe as dd

# ë°ì´í„° ë¡œë“œ
file_path = "../combined_dataset_v0.1.parquet"
ddf = dd.read_parquet(file_path)
df = ddf.compute()
# df = pd.read_parquet(file_path)
output_path = "../combined_dataset_v0.1_sample.csv"

# ìƒ˜í”Œë§í•  ì „ì²´ ê±°ë˜ ìˆ˜ ë° ë¹„ìœ¨ ì„¤ì •
n_samples = 10000  # ìƒ˜í”Œë§í•  ì „ì²´ ê±°ë˜ ìˆ˜
laundering_ratio = 0.10  # ìê¸ˆì„¸íƒ ê±°ë˜ ë¹„ìœ¨

# ì´ìƒê±°ë˜(ë¹„ì •ìƒ ê±°ë˜) ìƒ˜í”Œë§ ê°œìˆ˜ ê³„ì‚°
n_laundering_samples = int(n_samples * laundering_ratio)

# laundering_yn=1 ìƒ˜í”Œë§
df_fraud_sample = df[df["laundering_yn"] == 1].sample(
    n=min(n_laundering_samples, len(df[df["laundering_yn"] == 1])),
    random_state=42
)

# laundering_yn=0 ìƒ˜í”Œë§
df_normal_sample = df[df["laundering_yn"] == 0].sample(
    n=min(n_samples - n_laundering_samples, len(df[df["laundering_yn"] == 0])),
    random_state=42
)

df_sample = pd.concat([df_fraud_sample, df_normal_sample])
df_sample.to_csv(output_path, index=False)
print(f"ğŸ“ Sampled data saved to: {output_path}")
